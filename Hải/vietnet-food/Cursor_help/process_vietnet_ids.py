"""
Script xá»­ lÃ½ cáº­p nháº­t LexicalEntry ID vÃ  Synset ID cho VietNet Food
Dá»±a trÃªn file tá»« Ä‘iá»ƒn HoÃ ng PhÃª

LOGIC Má»šI:
1. LexicalEntry & Sense: So sÃ¡nh writtenForm vá»›i cá»™t "word" trong Excel
2. Synset: So sÃ¡nh Definition vá»›i cá»™t "meaning" trong Excel
3. Xá»­ lÃ½ chuá»—i: Loáº¡i bá» tiá»n tá»‘ [...], normalize khoáº£ng tráº¯ng
"""

import pandas as pd
import xml.etree.ElementTree as ET
from collections import defaultdict
import re
import unicodedata

def normalize_text(text):
    """
    Chuáº©n hÃ³a chuá»—i text Ä‘á»ƒ so sÃ¡nh:
    1. Loáº¡i bá» tiá»n tá»‘ dáº¡ng [...] á»Ÿ Ä‘áº§u (vd: [kng], [ph], [cÅ©])
    2. Loáº¡i bá» sá»‘ á»Ÿ Ä‘áº§u chuá»—i (vd: "1 ", "2 ")
    3. Normalize Unicode (NFC)
    4. Chuyá»ƒn vá» chá»¯ thÆ°á»ng
    5. Loáº¡i bá» dáº¥u cháº¥m, pháº©y, dáº¥u hai cháº¥m á»Ÿ cuá»‘i
    6. Strip khoáº£ng tráº¯ng Ä‘áº§u/cuá»‘i
    7. Thay khoáº£ng tráº¯ng kÃ©p thÃ nh Ä‘Æ¡n
    """
    if not text or pd.isna(text):
        return ""
    
    text = str(text)
    
    # 1. Loáº¡i bá» cÃ¡c tiá»n tá»‘ [...] á»Ÿ Ä‘áº§u
    # Pattern: báº¯t Ä‘áº§u báº±ng [, theo sau bá»Ÿi cÃ¡c kÃ½ tá»± khÃ´ng pháº£i ], káº¿t thÃºc báº±ng ]
    text = re.sub(r'^\[[^\]]+\]\s*', '', text)
    
    # 2. Loáº¡i bá» sá»‘ vÃ  khoáº£ng tráº¯ng á»Ÿ Ä‘áº§u chuá»—i (vd: "1 ", "12 ")
    text = re.sub(r'^\d+\s+', '', text)
    
    # 3. Normalize Unicode vá» dáº¡ng NFC
    text = unicodedata.normalize('NFC', text)
    
    # 4. Chuyá»ƒn vá» chá»¯ thÆ°á»ng Ä‘á»ƒ khÃ´ng phÃ¢n biá»‡t hoa/thÆ°á»ng
    text = text.lower()
    
    # 5. Strip khoáº£ng tráº¯ng Ä‘áº§u/cuá»‘i
    text = text.strip()
    
    # 6. Loáº¡i bá» cÃ¡c dáº¥u cÃ¢u á»Ÿ cuá»‘i (dáº¥u cháº¥m, dáº¥u 3 cháº¥m, dáº¥u pháº©y, dáº¥u hai cháº¥m)
    text = re.sub(r'[.,;:]+$', '', text)
    text = text.strip()  # Strip láº¡i sau khi loáº¡i bá» dáº¥u cÃ¢u
    
    # 7. Thay nhiá»u khoáº£ng tráº¯ng liÃªn tiáº¿p thÃ nh 1
    text = re.sub(r'\s+', ' ', text)
    
    return text

def main():
    print("=" * 80)
    print("ðŸ“‹ SCRIPT Xá»¬ LÃ Cáº¬P NHáº¬T ID CHO VIETNET FOOD (LOGIC Má»šI)")
    print("=" * 80)
    
    # === 1ï¸âƒ£ Äá»c dá»¯ liá»‡u tá»« Excel ===
    print("\n[1/5] Äá»c dá»¯ liá»‡u tá»« Excel...")
    excel_path = "data/edit_id/tu_dien_Hoang_Phe.xlsx"
    df = pd.read_excel(excel_path)
    
    # Táº¡o mapping {word: [list of indices]}
    word_to_indices = {}
    for idx, row in df.iterrows():
        word = normalize_text(row["word"])
        if word:
            if word not in word_to_indices:
                word_to_indices[word] = []
            word_to_indices[word].append(idx + 1)  # index báº¯t Ä‘áº§u tá»« 1
    
    # Táº¡o mapping {normalized_meaning: [list of indices]}
    # KEY: normalized meaning (Ä‘Ã£ loáº¡i bá» tiá»n tá»‘)
    # VALUE: list of indices
    meaning_to_indices = {}
    for idx, row in df.iterrows():
        meaning = normalize_text(row["meaning"])
        if meaning:
            if meaning not in meaning_to_indices:
                meaning_to_indices[meaning] = []
            meaning_to_indices[meaning].append(idx + 1)
    
    print(f"   âœ“ Tá»•ng sá»‘ dÃ²ng trong Excel: {len(df)}")
    print(f"   âœ“ Sá»‘ tá»« khÃ¡c nhau: {len(word_to_indices)}")
    print(f"   âœ“ Sá»‘ nghÄ©a khÃ¡c nhau: {len(meaning_to_indices)}")
    
    # === 2ï¸âƒ£ Äá»c XML ===
    print("\n[2/5] Äá»c file XML gá»‘c...")
    xml_path = "vietnet_food (thá»§ cÃ´ng).xml"
    tree = ET.parse(xml_path)
    root = tree.getroot()
    
    ns = {"dc": "https://globalwordnet.github.io/schemas/dc/"}
    lexicon = root.find(".//Lexicon", ns)
    
    # === 3ï¸âƒ£ Xá»­ lÃ½ LexicalEntry ID ===
    print("\n[3/5] Xá»­ lÃ½ LexicalEntry ID vÃ  Sense ID...")
    
    entry_not_found = []  # KhÃ´ng tÃ¬m Ä‘Æ°á»£c trong Excel
    entry_more_than_1 = []  # TÃ¬m Ä‘Æ°á»£c >= 2 dÃ²ng
    entry_updated = 0
    
    for entry in lexicon.findall("LexicalEntry", ns):
        lemma = entry.find("Lemma", ns)
        if lemma is None:
            continue
        
        word_raw = lemma.attrib.get("writtenForm", "")
        word = normalize_text(word_raw)
        pos = lemma.attrib.get("partOfSpeech", "")
        old_entry_id = entry.attrib.get("id", "")
        
        if pos != "n":
            continue
        
        # TÃ¬m trong Excel (sá»­ dá»¥ng normalized word)
        if word not in word_to_indices:
            # KhÃ´ng tÃ¬m tháº¥y
            entry_not_found.append({
                "word": word,
                "old_id": old_entry_id
            })
        elif len(word_to_indices[word]) == 1:
            # TÃ¬m Ä‘Æ°á»£c Ä‘Ãºng 1 dÃ²ng
            index = word_to_indices[word][0]
            new_entry_id = f"vietnet-food-{index:08d}"
            entry.set("id", new_entry_id)
            
            # Cáº­p nháº­t Sense ID
            for sense in entry.findall("Sense", ns):
                sense.set("id", f"{new_entry_id}-1")
            
            entry_updated += 1
        else:
            # TÃ¬m Ä‘Æ°á»£c >= 2 dÃ²ng
            entry_more_than_1.append({
                "word": word,
                "old_id": old_entry_id,
                "indices": word_to_indices[word],
                "count": len(word_to_indices[word])
            })
    
    print(f"   âœ“ ÄÃ£ cáº­p nháº­t: {entry_updated} LexicalEntry")
    print(f"   âš ï¸  KhÃ´ng tÃ¬m tháº¥y: {len(entry_not_found)} entries")
    print(f"   âš ï¸  TÃ¬m Ä‘Æ°á»£c >= 2: {len(entry_more_than_1)} entries")
    
    # === 4ï¸âƒ£ Xá»­ lÃ½ Synset ID ===
    print("\n[4/5] Xá»­ lÃ½ Synset ID...")
    
    synset_not_found = []  # KhÃ´ng tÃ¬m Ä‘Æ°á»£c trong Excel
    synset_more_than_1 = []  # TÃ¬m Ä‘Æ°á»£c >= 2 dÃ²ng
    synset_updated = 0
    synset_id_mapping = {}  # old_synset_id -> new_synset_id
    
    for synset in lexicon.findall("Synset", ns):
        old_synset_id = synset.attrib.get("id", "")
        
        # Láº¥y Definition
        definition_elem = synset.find("Definition", ns)
        if definition_elem is None or not definition_elem.text:
            continue
        
        definition_raw = definition_elem.text
        definition = normalize_text(definition_raw)
        
        # TÃ¬m trong Excel theo normalized meaning
        if definition not in meaning_to_indices:
            # KhÃ´ng tÃ¬m tháº¥y
            synset_not_found.append({
                "definition": definition[:100] + "..." if len(definition) > 100 else definition,
                "old_id": old_synset_id
            })
        elif len(meaning_to_indices[definition]) == 1:
            # TÃ¬m Ä‘Æ°á»£c Ä‘Ãºng 1 dÃ²ng
            index = meaning_to_indices[definition][0]
            new_synset_id = f"vietnet-food-{index:08d}-n"
            synset.set("id", new_synset_id)
            synset_id_mapping[old_synset_id] = new_synset_id
            synset_updated += 1
        else:
            # TÃ¬m Ä‘Æ°á»£c >= 2 dÃ²ng
            synset_more_than_1.append({
                "definition": definition[:100] + "..." if len(definition) > 100 else definition,
                "old_id": old_synset_id,
                "indices": meaning_to_indices[definition],
                "count": len(meaning_to_indices[definition])
            })
    
    print(f"   âœ“ ÄÃ£ cáº­p nháº­t: {synset_updated} Synset")
    print(f"   âš ï¸  KhÃ´ng tÃ¬m tháº¥y: {len(synset_not_found)} synsets")
    print(f"   âš ï¸  TÃ¬m Ä‘Æ°á»£c >= 2: {len(synset_more_than_1)} synsets")
    
    # === 4.5ï¸âƒ£ Cáº­p nháº­t tham chiáº¿u Ä‘áº¿n Synset ===
    print("\n   â†’ Cáº­p nháº­t tham chiáº¿u trong Sense...")
    updated_sense_refs = 0
    for entry in lexicon.findall("LexicalEntry", ns):
        for sense in entry.findall("Sense", ns):
            old_synset_id = sense.attrib.get("synset", "")
            if old_synset_id in synset_id_mapping:
                sense.set("synset", synset_id_mapping[old_synset_id])
                updated_sense_refs += 1
    
    print(f"   âœ“ ÄÃ£ cáº­p nháº­t: {updated_sense_refs} tham chiáº¿u trong Sense")
    
    print("   â†’ Cáº­p nháº­t tham chiáº¿u trong SynsetRelation...")
    updated_relation_refs = 0
    for synset in lexicon.findall("Synset", ns):
        for relation in synset.findall("SynsetRelation", ns):
            old_target = relation.attrib.get("target", "")
            if old_target in synset_id_mapping:
                relation.set("target", synset_id_mapping[old_target])
                updated_relation_refs += 1
    
    print(f"   âœ“ ÄÃ£ cáº­p nháº­t: {updated_relation_refs} tham chiáº¿u trong SynsetRelation")
    
    # === 5ï¸âƒ£ Xuáº¥t káº¿t quáº£ ===
    print("\n[5/5] Xuáº¥t káº¿t quáº£...")
    
    # Táº¡o thÆ° má»¥c output náº¿u chÆ°a cÃ³
    import os
    output_dir = "Cursor_help"
    os.makedirs(output_dir, exist_ok=True)
    
    # Xuáº¥t file XML má»›i
    output_xml = os.path.join(output_dir, "vietnet_food_final.xml")
    tree.write(output_xml, encoding="UTF-8", xml_declaration=True)
    print(f"   âœ“ ÄÃ£ xuáº¥t file XML: {output_xml}")
    
    # Xuáº¥t cÃ¡c file phá»¥ cho LexicalEntry
    not_found_file = os.path.join(output_dir, "not_found.xlsx")
    pd.DataFrame(entry_not_found).to_excel(not_found_file, index=False)
    print(f"   âœ“ ÄÃ£ xuáº¥t file: {not_found_file} ({len(entry_not_found)} entries)")
    
    more_than_1_file = os.path.join(output_dir, "more_than_1.xlsx")
    pd.DataFrame(entry_more_than_1).to_excel(more_than_1_file, index=False)
    print(f"   âœ“ ÄÃ£ xuáº¥t file: {more_than_1_file} ({len(entry_more_than_1)} entries)")
    
    # Xuáº¥t cÃ¡c file phá»¥ cho Synset
    synset_not_found_file = os.path.join(output_dir, "synset_not_found.xlsx")
    pd.DataFrame(synset_not_found).to_excel(synset_not_found_file, index=False)
    print(f"   âœ“ ÄÃ£ xuáº¥t file: {synset_not_found_file} ({len(synset_not_found)} synsets)")
    
    synset_more_than_1_file = os.path.join(output_dir, "synset_more_than_1.xlsx")
    pd.DataFrame(synset_more_than_1).to_excel(synset_more_than_1_file, index=False)
    print(f"   âœ“ ÄÃ£ xuáº¥t file: {synset_more_than_1_file} ({len(synset_more_than_1)} synsets)")
    
    # === ðŸ“Š Tá»•ng káº¿t ===
    print("\n" + "=" * 80)
    print("âœ… HOÃ€N THÃ€NH!")
    print("=" * 80)
    print(f"""
ðŸ“ Tá»”NG Káº¾T:

ðŸ”¹ LEXICAL ENTRY:
   â€¢ ÄÃ£ cáº­p nháº­t: {entry_updated}
   â€¢ KhÃ´ng tÃ¬m tháº¥y: {len(entry_not_found)}
   â€¢ TÃ¬m Ä‘Æ°á»£c >= 2: {len(entry_more_than_1)}

ðŸ”¹ SYNSET:
   â€¢ ÄÃ£ cáº­p nháº­t: {synset_updated}
   â€¢ KhÃ´ng tÃ¬m tháº¥y: {len(synset_not_found)}
   â€¢ TÃ¬m Ä‘Æ°á»£c >= 2: {len(synset_more_than_1)}

ðŸ”¹ THAM CHIáº¾U:
   â€¢ Sense.synset Ä‘Ã£ cáº­p nháº­t: {updated_sense_refs}
   â€¢ SynsetRelation.target Ä‘Ã£ cáº­p nháº­t: {updated_relation_refs}

ðŸ“‚ CÃC FILE ÄÃƒ Táº O (trong thÆ° má»¥c {output_dir}/):
   â€¢ vietnet_food_final.xml - File XML Ä‘Ã£ cáº­p nháº­t
   â€¢ not_found.xlsx - LexicalEntry khÃ´ng tÃ¬m tháº¥y
   â€¢ more_than_1.xlsx - LexicalEntry tÃ¬m Ä‘Æ°á»£c >= 2
   â€¢ synset_not_found.xlsx - Synset khÃ´ng tÃ¬m tháº¥y
   â€¢ synset_more_than_1.xlsx - Synset tÃ¬m Ä‘Æ°á»£c >= 2
    """)

if __name__ == "__main__":
    main()

