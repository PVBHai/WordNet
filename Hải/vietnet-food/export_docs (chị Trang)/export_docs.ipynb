{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Export VietNet Food Data to Text Format\n",
        "\n",
        "Xu·∫•t to√†n b·ªô d·ªØ li·ªáu VietNet Food th√†nh ƒë·ªãnh d·∫°ng vƒÉn b·∫£n:\n",
        "\n",
        "```\n",
        "<number_of_tab> (<level>) {<lemma1>, <lemma2>, ...} [<synset_id>]: <definition>\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Read [##############################] (4671/4671) \n",
            "\u001b[KAdded vietnet-food:1.0 (VietNet Vietnamese Food Lexicon (All))ionssours\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "T·ªïng s·ªë synsets: 590\n",
            "S·ªë l∆∞·ª£ng root synsets: 2\n",
            "\n",
            "‚úÖ ƒê√£ xu·∫•t 590 d√≤ng d·ªØ li·ªáu v√†o file: vietnet_food_export.txt\n",
            "\n",
            "üìÑ Preview (20 d√≤ng ƒë·∫ßu):\n",
            "================================================================================\n",
            "(0) {th·ª©c ƒÉn, ch·∫•t} [vietnet-food-00045020-n]: th·ª© c√≥ ch·ª©a ch·∫•t dinh d∆∞·ª°ng v√† c√≥ th·ªÉ ti√™u h√≥a ƒë∆∞·ª£c, d√πng ƒë·ªÉ nu√¥i s·ªëng con ng∆∞·ªùi v√† ƒë·ªông v·∫≠t, n√≥i chung\n",
            "\t(1) {th·ª±c ph·∫©m} [vietnet-food-00045060-n]: c√°c th·ª© d√πng ƒë·ªÉ ch·∫ø bi·∫øn th√†nh m√≥n ƒÉn, nh∆∞ th·ªãt, c√°, tr·ª©ng, v.v. [n√≥i kh√°i qu√°t]; ph√¢n bi·ªát v·ªõi l∆∞∆°ng th·ª±c\n",
            "\t\t(2) {n√¥ng s·∫£n, n√¥ng ph·∫©m} [vietnet-food-00034540-n]: s·∫£n ph·∫©m n√¥ng nghi·ªáp, nh∆∞ g·∫°o, th·ªãt, tr·ª©ng, rau, hoa qu·∫£, v.v. [n√≥i kh√°i qu√°t]\n",
            "\t\t\t(3) {s√∫c s·∫£n} [vietnet-food-00040488-n]: s·∫£n ph·∫©m th·ªãt gia s√∫c\n",
            "\t\t\t\t(4) {c·∫ßy} [vietnet-food-00006363-n]: ch√≥, v·ªÅ m·∫∑t ƒë·ªÉ ƒÉn th·ªãt\n",
            "\t\t\t\t(4) {gi√≤} [vietnet-food-00018716-n]: c·∫≥ng ch√¢n gia s√∫c ho·∫∑c gia c·∫ßm\n",
            "\t\t\t\t(4) {n·∫°c} [vietnet-food-00030509-n]: th·ªãt kh√¥ng c√≥ m·ª°\n",
            "\t\t\t\t(4) {thƒÉn} [vietnet-food-00042705-n]: ph·∫ßn th·ªãt to√†n n·∫°c ƒë∆∞·ª£c l·ªçc ra ·ªü ph·∫ßn l∆∞ng c·ªßa s√∫c v·∫≠t khi m·ªï th·ªãt\n",
            "\t\t\t\t(4) {n·ªçng} [vietnet-food-00034330-n]: khoanh th·ªãt c·∫Øt ra ·ªü c·ªï gia s√∫c gi·∫øt th·ªãt [th∆∞·ªùng l√† tr√¢u, b√≤, l·ª£n]\n",
            "\t\t\t\t(4) {ba ch·ªâ, ba r·ªçi} [vietnet-food-00000981-n]: ph·∫ßn th·ªãt l·ª£n ·ªü v√πng b·ª•ng, c√≥ ba th·ªõ n·∫°c xen v·ªõi m·ª°\n",
            "\t\t\t\t(4) {ch√¢n gi√≤, c·∫≥ng gi√≤} [vietnet-food-00006912-n]: ch√¢n l·ª£n ƒë√£ l√†m th·ªãt\n",
            "\t\t\t\t(4) {m√≥ng gi√≤} [vietnet-food-00029686-n]: ƒëo·∫°n ng·∫Øn c·ªßa ch√¢n gi√≤ l·ª£n t·ª´ khu·ª∑u ƒë·∫øn c√°c m√≥ng\n",
            "\t\t\t\t(4) {s·∫•n} [vietnet-food-00039604-n]: ph·∫ßn th·ªãt c√≥ n·∫°c n·∫±m tr√™n m·ª° ph·∫ßn ·ªü l∆∞ng, m√¥ng v√† vai l·ª£n\n",
            "\t\t\t\t(4) {n√¢y} [vietnet-food-00030879-n]: th·ªãt m·ª° b√®o nh√®o ·ªü b·ª•ng l·ª£n\n",
            "\t\t\t\t(4) {n·∫ßm} [vietnet-food-00030827-n]: ph·∫ßn th·ªãt ·ªü gi·ªØa b·ª•ng l·ª£n, tr√¢u, b√≤, v.v.\n",
            "\t\t\t\t(4) {b√¨} [vietnet-food-00002947-n]: da c·ªßa l·ª£n, b√≤, v.v. d√πng l√†m th·ª©c ƒÉn\n",
            "\t\t\t\t(4) {n·∫°m} [vietnet-food-00030571-n]: th·ªãt ·ªü s∆∞·ªùn b√≤, c√≥ l·∫´n c·∫£ g√¢n\n",
            "\t\t\t\t(4) {g√†u} [vietnet-food-00017441-n]: th·ªãt c√≥ l·∫´n m·ª° ·ªü ng·ª±c b√≤\n",
            "\t\t\t\t(4) {l√≤ng} [vietnet-food-00026946-n]: nh·ªØng b·ªô ph·∫≠n trong b·ª•ng c·ªßa con v·∫≠t gi·∫øt th·ªãt, d√πng l√†m th·ª©c ƒÉn [n√≥i t·ªïng qu√°t]\n",
            "\t\t\t\t\t(5) {l√≤ng} [vietnet-food-00026947-n]: ru·ªôt l·ª£n, d√πng l√†m th·ª©c ƒÉn\n",
            "================================================================================\n",
            "\n",
            "üìä Th·ªëng k√™:\n",
            "   - T·ªïng s·ªë d√≤ng ƒë√£ xu·∫•t: 590\n",
            "   - File ƒë∆∞·ª£c l∆∞u t·∫°i: vietnet_food_export.txt\n",
            "\n",
            "üí° B·∫°n c√≥ th·ªÉ m·ªü file n√†y b·∫±ng Word ho·∫∑c Google Docs ƒë·ªÉ xem to√†n b·ªô d·ªØ li·ªáu.\n"
          ]
        }
      ],
      "source": [
        "# Import v√† x·ª≠ l√≠ d·ªØ li·ªáu\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Add components to path\n",
        "sys.path.append(os.path.join(os.getcwd(), 'components'))\n",
        "\n",
        "from components.utils_wn import *\n",
        "from components.class_Node import *\n",
        "from components.class_NodeFamily import *\n",
        "import wn\n",
        "\n",
        "# Initialize lexicon\n",
        "wn.remove('vietnet-food:1.0')\n",
        "wn.add('../vietnet_food (th·ªß c√¥ng).xml')\n",
        "lexicon = wn.Wordnet('vietnet-food:1.0')\n",
        "\n",
        "# Get all root synsets (synsets with no hypernyms)\n",
        "all_synsets = list(lexicon.synsets())\n",
        "root_synsets = [syn for syn in all_synsets if not syn.hypernyms()]\n",
        "\n",
        "print(f\"T·ªïng s·ªë synsets: {len(all_synsets)}\")\n",
        "print(f\"S·ªë l∆∞·ª£ng root synsets: {len(root_synsets)}\")\n",
        "\n",
        "# Build tree with hyponym relationship and maximum depth\n",
        "families = NodeFamily(root_synsets, 'hyponym', max_recursive=100)\n",
        "\n",
        "# Function to export nodes to text with proper formatting\n",
        "def export_to_text(nodes, output_file='vietnet_food_export.txt'):\n",
        "    \"\"\"\n",
        "    Export node tree to text file with format:\n",
        "    <tabs> (<level>) {lemmas} [synset_id]: definition\n",
        "    \"\"\"\n",
        "    lines = []\n",
        "    \n",
        "    def traverse_node(node, depth=0):\n",
        "        # Calculate level from root (node._level is absolute level from root)\n",
        "        level = node._level - 1  # Convert to 0-based level\n",
        "        \n",
        "        # Create tabs for indentation\n",
        "        tabs = '\\t' * level\n",
        "        \n",
        "        # Get lemmas\n",
        "        lemmas = node._lemmas\n",
        "        \n",
        "        # Get synset ID\n",
        "        synset_id = node._synset.id\n",
        "        \n",
        "        # Get definition\n",
        "        definition = node._definition\n",
        "        \n",
        "        # Format: <tabs> (<level>) {lemmas} [synset_id]: definition\n",
        "        line = f\"{tabs}({level}) {{{lemmas}}} [{synset_id}]: {definition}\"\n",
        "        lines.append(line)\n",
        "        \n",
        "        # Recursively traverse children\n",
        "        if node.children:\n",
        "            for child in node.children:\n",
        "                traverse_node(child, depth + 1)\n",
        "    \n",
        "    # Traverse all root nodes\n",
        "    for node in nodes:\n",
        "        traverse_node(node)\n",
        "    \n",
        "    # Write to file\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        f.write('\\n'.join(lines))\n",
        "    \n",
        "    print(f\"\\n‚úÖ ƒê√£ xu·∫•t {len(lines)} d√≤ng d·ªØ li·ªáu v√†o file: {output_file}\")\n",
        "    print(f\"\\nüìÑ Preview (20 d√≤ng ƒë·∫ßu):\")\n",
        "    print(\"=\" * 80)\n",
        "    for i, line in enumerate(lines[:20]):\n",
        "        print(line)\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    return lines\n",
        "\n",
        "# Export data\n",
        "exported_lines = export_to_text(families.nodes, 'vietnet_food_export.txt')\n",
        "\n",
        "print(f\"\\nüìä Th·ªëng k√™:\")\n",
        "print(f\"   - T·ªïng s·ªë d√≤ng ƒë√£ xu·∫•t: {len(exported_lines)}\")\n",
        "print(f\"   - File ƒë∆∞·ª£c l∆∞u t·∫°i: vietnet_food_export.txt\")\n",
        "print(f\"\\nüí° B·∫°n c√≥ th·ªÉ m·ªü file n√†y b·∫±ng Word ho·∫∑c Google Docs ƒë·ªÉ xem to√†n b·ªô d·ªØ li·ªáu.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "TH·ªêNG K√ä C·∫§U TR√öC PH√ÇN C·∫§P H·ªÜ TH·ªêNG NH√ÉN NG·ªÆ NGHƒ®A\n",
            "================================================================================\n",
            "\n",
            "üìä B·∫£ng 10. C·∫•u tr√∫c ph√¢n c·∫•p h·ªá th·ªëng nh·∫≠n ng·ªØ nghƒ©a cho nh√°nh \"th·ª©c ƒÉn, ch·∫•t\"\n",
            "--------------------------------------------------------------------------------\n",
            "T·∫ßng  S·ªë m·ª•c t·ª´ danh t·ª´  S·ªë ƒë·ªãnh nghƒ©a\n",
            "   0                  2              1\n",
            "   1                  3              3\n",
            "   2                 43             37\n",
            "   3                154            121\n",
            "   4                124            103\n",
            "   5                  5              5\n",
            "T·ªïng                331            270\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üí° Nh√°nh \"th·ª©c ƒÉn, ch·∫•t\" bao g·ªìm 331 m·ª•c t·ª´ v·ªõi 270 ƒë·ªãnh nghƒ©a, t·∫≠p trung ·ªü t·∫ßng 3 (154 m·ª•c t·ª´, 121 ƒë·ªãnh nghƒ©a) v√† t·∫ßng 4 (124 m·ª•c t·ª´, 103 ƒë·ªãnh nghƒ©a) v√† k·∫øt th√∫c ·ªü t·∫ßng 5.\n",
            "\n",
            "\n",
            "\n",
            "üìä B·∫£ng 11. C·∫•u tr√∫c ph√¢n c·∫•p h·ªá th·ªëng nh·∫≠n ng·ªØ nghƒ©a cho nh√°nh \"th·ª©c ƒÉn, th·ª©c\"\n",
            "--------------------------------------------------------------------------------\n",
            "T·∫ßng  S·ªë m·ª•c t·ª´ danh t·ª´  S·ªë ƒë·ªãnh nghƒ©a\n",
            "   0                  2              1\n",
            "   1                 30             25\n",
            "   2                133            112\n",
            "   3                201            173\n",
            "   4                  7              6\n",
            "T·ªïng                373            317\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üí° Nh√°nh \"th·ª©c ƒÉn, th·ª©c\" bao g·ªìm 373 m·ª•c t·ª´ v·ªõi 317 ƒë·ªãnh nghƒ©a, t·∫≠p trung ·ªü t·∫ßng 3 (201 m·ª•c t·ª´, 173 ƒë·ªãnh nghƒ©a) v√† t·∫ßng 2 (133 m·ª•c t·ª´, 112 ƒë·ªãnh nghƒ©a) v√† k·∫øt th√∫c ·ªü t·∫ßng 4.\n",
            "\n",
            "\n",
            "================================================================================\n",
            "üìà TH·ªêNG K√ä T·ªîNG TH·ªÇ\n",
            "================================================================================\n",
            "T·∫ßng  S·ªë m·ª•c t·ª´ danh t·ª´  S·ªë ƒë·ªãnh nghƒ©a\n",
            "   0                  4              2\n",
            "   1                 33             28\n",
            "   2                176            149\n",
            "   3                355            294\n",
            "   4                131            109\n",
            "   5                  5              5\n",
            "T·ªïng                704            587\n",
            "================================================================================\n",
            "\n",
            "‚úÖ T·ªïng c·ªông: 704 m·ª•c t·ª´ danh t·ª´ | 587 ƒë·ªãnh nghƒ©a ri√™ng bi·ªát\n",
            "üìö T·ªïng s·ªë synsets: 590\n",
            "üå≥ S·ªë nh√°nh g·ªëc: 2\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TH·ªêNG K√ä CH√çNH X√ÅC - ƒê·∫æM THEO S·ªê L·∫¶N XU·∫§T HI·ªÜN (KH√îNG LO·∫†I B·ªé TR√ôNG L·∫∂P)\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "def analyze_tree_structure_exact(nodes, branch_name=\"\"):\n",
        "    \"\"\"\n",
        "    Ph√¢n t√≠ch c·∫•u tr√∫c ph√¢n c·∫•p c·ªßa c√¢y - ƒê·∫æM CH√çNH X√ÅC theo s·ªë l·∫ßn xu·∫•t hi·ªán\n",
        "    KH√îNG lo·∫°i b·ªè m·ª•c t·ª´ ho·∫∑c ƒë·ªãnh nghƒ©a tr√πng nhau\n",
        "    \"\"\"\n",
        "    level_stats = defaultdict(lambda: {'lemmas_count': 0, 'definitions_count': 0, 'synsets_count': 0})\n",
        "    \n",
        "    def traverse_and_count(node):\n",
        "        level = node._level - 1  # Convert to 0-based\n",
        "        \n",
        "        # ƒê·∫øm s·ªë synsets (m·ªói node = 1 synset)\n",
        "        level_stats[level]['synsets_count'] += 1\n",
        "        \n",
        "        # ƒê·∫øm s·ªë ƒë·ªãnh nghƒ©a (m·ªói synset c√≥ 1 ƒë·ªãnh nghƒ©a, ƒë·∫øm t·∫•t c·∫£ k·ªÉ c·∫£ tr√πng)\n",
        "        if node._definition:\n",
        "            level_stats[level]['definitions_count'] += 1\n",
        "        \n",
        "        # ƒê·∫øm s·ªë m·ª•c t·ª´ (lemmas) - ƒë·∫øm t·∫•t c·∫£ c√°c lemma k·ªÉ c·∫£ tr√πng\n",
        "        lemmas_list = node._lemmas.split(', ')\n",
        "        level_stats[level]['lemmas_count'] += len(lemmas_list)\n",
        "        \n",
        "        # ƒê·ªá quy v·ªõi c√°c con\n",
        "        if node.children:\n",
        "            for child in node.children:\n",
        "                traverse_and_count(child)\n",
        "    \n",
        "    # Duy·ªát t·∫•t c·∫£ c√°c node g·ªëc\n",
        "    for node in nodes:\n",
        "        traverse_and_count(node)\n",
        "    \n",
        "    # T·∫°o b·∫£ng th·ªëng k√™\n",
        "    max_level = max(level_stats.keys()) if level_stats else 0\n",
        "    \n",
        "    data = []\n",
        "    total_lemmas = 0\n",
        "    total_definitions = 0\n",
        "    total_synsets = 0\n",
        "    \n",
        "    for level in range(max_level + 1):\n",
        "        if level in level_stats:\n",
        "            num_lemmas = level_stats[level]['lemmas_count']\n",
        "            num_definitions = level_stats[level]['definitions_count']\n",
        "            num_synsets = level_stats[level]['synsets_count']\n",
        "        else:\n",
        "            num_lemmas = 0\n",
        "            num_definitions = 0\n",
        "            num_synsets = 0\n",
        "        \n",
        "        data.append({\n",
        "            'T·∫ßng': level,\n",
        "            'S·ªë m·ª•c t·ª´ danh t·ª´': num_lemmas,\n",
        "            'S·ªë ƒë·ªãnh nghƒ©a': num_definitions\n",
        "        })\n",
        "        \n",
        "        total_lemmas += num_lemmas\n",
        "        total_definitions += num_definitions\n",
        "        total_synsets += num_synsets\n",
        "    \n",
        "    # Th√™m d√≤ng t·ªïng\n",
        "    data.append({\n",
        "        'T·∫ßng': 'T·ªïng',\n",
        "        'S·ªë m·ª•c t·ª´ danh t·ª´': total_lemmas,\n",
        "        'S·ªë ƒë·ªãnh nghƒ©a': total_definitions\n",
        "    })\n",
        "    \n",
        "    df = pd.DataFrame(data)\n",
        "    \n",
        "    return df, total_lemmas, total_definitions, total_synsets\n",
        "\n",
        "# Ph√¢n t√≠ch to√†n b·ªô c√¢y\n",
        "print(\"=\"*80)\n",
        "print(\"TH·ªêNG K√ä C·∫§U TR√öC PH√ÇN C·∫§P H·ªÜ TH·ªêNG NH√ÉN NG·ªÆ NGHƒ®A\")\n",
        "print(\"(ƒê·∫æM CH√çNH X√ÅC - KH√îNG LO·∫†I B·ªé TR√ôNG L·∫∂P)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Ph√¢n t√≠ch theo t·ª´ng nh√°nh g·ªëc\n",
        "for idx, root_node in enumerate(families.nodes):\n",
        "    root_lemmas = root_node._lemmas\n",
        "    root_definition = root_node._definition\n",
        "    \n",
        "    print(f\"\\nüìä B·∫£ng {idx + 10}. C·∫•u tr√∫c ph√¢n c·∫•p h·ªá th·ªëng nh√£n ng·ªØ nghƒ©a cho nh√°nh \\\"{root_lemmas}\\\"\")\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    # Ph√¢n t√≠ch nh√°nh n√†y\n",
        "    df, total_lemmas, total_defs, total_synsets = analyze_tree_structure_exact([root_node], root_lemmas)\n",
        "    \n",
        "    # Hi·ªÉn th·ªã b·∫£ng\n",
        "    print(df.to_string(index=False))\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    # T√¨m max level\n",
        "    max_level = df[df['T·∫ßng'] != 'T·ªïng']['T·∫ßng'].max()\n",
        "    \n",
        "    # T√¨m c√°c t·∫ßng c√≥ s·ªë m·ª•c t·ª´ nhi·ªÅu nh·∫•t (kh√¥ng t√≠nh t·∫ßng 0 v√† T·ªïng)\n",
        "    df_levels = df[df['T·∫ßng'] != 'T·ªïng'].copy()\n",
        "    df_levels = df_levels[df_levels['T·∫ßng'] != 0]\n",
        "    \n",
        "    if len(df_levels) > 0:\n",
        "        # S·∫Øp x·∫øp theo s·ªë m·ª•c t·ª´ gi·∫£m d·∫ßn\n",
        "        df_sorted = df_levels.sort_values('S·ªë m·ª•c t·ª´ danh t·ª´', ascending=False)\n",
        "        top_levels = df_sorted.head(2)\n",
        "        \n",
        "        summary_parts = []\n",
        "        for _, row in top_levels.iterrows():\n",
        "            level = int(row['T·∫ßng'])\n",
        "            num_lemmas = int(row['S·ªë m·ª•c t·ª´ danh t·ª´'])\n",
        "            num_defs = int(row['S·ªë ƒë·ªãnh nghƒ©a'])\n",
        "            summary_parts.append(f\"t·∫ßng {level} ({num_lemmas} m·ª•c t·ª´, {num_defs} ƒë·ªãnh nghƒ©a)\")\n",
        "        \n",
        "        summary = f\"Nh√°nh \\\"{root_lemmas}\\\" bao g·ªìm {total_lemmas} m·ª•c t·ª´ v·ªõi {total_defs} ƒë·ªãnh nghƒ©a, \"\n",
        "        summary += f\"t·∫≠p trung ·ªü {' v√† '.join(summary_parts)}\"\n",
        "        summary += f\" v√† k·∫øt th√∫c ·ªü t·∫ßng {max_level}.\"\n",
        "        \n",
        "        print(f\"\\nüí° {summary}\")\n",
        "    \n",
        "    print(\"\\n\")\n",
        "\n",
        "# Th·ªëng k√™ t·ªïng th·ªÉ\n",
        "print(\"=\"*80)\n",
        "print(\"üìà TH·ªêNG K√ä T·ªîNG TH·ªÇ\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "df_total, total_lemmas_all, total_defs_all, total_synsets_all = analyze_tree_structure_exact(families.nodes, \"To√†n b·ªô\")\n",
        "print(df_total.to_string(index=False))\n",
        "print(\"=\"*80)\n",
        "print(f\"\\n‚úÖ T·ªïng c·ªông: {total_lemmas_all} m·ª•c t·ª´ danh t·ª´ | {total_defs_all} ƒë·ªãnh nghƒ©a\")\n",
        "print(f\"üìö T·ªïng s·ªë synsets: {len(all_synsets)}\")\n",
        "print(f\"üå≥ S·ªë nh√°nh g·ªëc: {len(root_synsets)}\")\n",
        "print(\"\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
